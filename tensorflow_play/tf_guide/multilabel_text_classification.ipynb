{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546c829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4174e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \n",
       "0           ['cs.CV', 'cs.LG']  \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
       "2           ['cs.CV', 'cs.AI']  \n",
       "3                    ['cs.CV']  \n",
       "4           ['cs.CV', 'cs.LG']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "arxiv_data = pd.read_csv(\n",
    "    \"https://github.com/soumik12345/multi-label-text-classification/releases/download/v0.2/arxiv_data.csv\"\n",
    ")\n",
    "arxiv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34aeef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51774 rows in the dataset.\n",
      "There are 12802 duplicate titles.\n"
     ]
    }
   ],
   "source": [
    "# Data information \n",
    "print(f\"There are {len(arxiv_data)} rows in the dataset.\")\n",
    "total_duplicate_titles = sum(arxiv_data[\"titles\"].duplicated())\n",
    "print(f\"There are {total_duplicate_titles} duplicate titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d85e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38972 rows in the deduplicated dataset.\n",
      "2321\n",
      "3157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36651, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "arxiv_data = arxiv_data[~arxiv_data[\"titles\"].duplicated()]\n",
    "print(f\"There are {len(arxiv_data)} rows in the deduplicated dataset.\")\n",
    "\n",
    "# There are some terms with occurrence as low as 1.\n",
    "print(sum(arxiv_data[\"terms\"].value_counts() == 1))\n",
    "\n",
    "# How many unique terms?\n",
    "print(arxiv_data[\"terms\"].nunique())\n",
    "\n",
    "# Drop lowest occurenence \n",
    "arxiv_data_filtered = arxiv_data.groupby(\"terms\").filter(lambda x: len(x) > 1)\n",
    "arxiv_data_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e16039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['cs.CV', 'cs.LG']), list(['cs.CV', 'cs.AI', 'cs.LG']),\n",
       "       list(['cs.CV', 'cs.AI']), list(['cs.CV']),\n",
       "       list(['cs.CV', 'cs.LG'])], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More preprocessing, convert raw strings to list of strings for terms \n",
    "arxiv_data_filtered[\"terms\"] = arxiv_data_filtered[\"terms\"].apply(\n",
    "    lambda x: literal_eval(x)\n",
    ")\n",
    "arxiv_data_filtered[\"terms\"].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065595c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 32985\n",
      "Number of rows in validation set: 1833\n",
      "Number of rows in test set: 1833\n"
     ]
    }
   ],
   "source": [
    "# Split data (Stratification to deal with class imbalance)\n",
    "test_split = 0.1\n",
    "\n",
    "# Initial train and test split.\n",
    "train_df, test_df = train_test_split(\n",
    "    arxiv_data_filtered,\n",
    "    test_size=test_split,\n",
    "    stratify=arxiv_data_filtered[\"terms\"].values,\n",
    ")\n",
    "\n",
    "# Splitting the test set further into validation\n",
    "# and new test sets.\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b63308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 12:12:44.405246: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-07 12:12:44.480962: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "\n",
      "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.CR', 'math.OC', 'eess.SP', 'cs.GR', 'cs.SI', 'cs.MM', 'cs.SY', 'cs.IR', 'cs.MA', 'eess.SY', 'cs.HC', 'math.IT', 'cs.IT', 'cs.DC', 'stat.AP', 'cs.CY', 'stat.TH', 'math.ST', 'stat.ME', 'eess.AS', 'cs.SD', 'q-bio.QM', 'q-bio.NC', 'cs.DS', 'cs.GT', 'cs.CG', 'cs.SE', 'cs.NI', 'I.2.6', 'stat.CO', 'math.NA', 'cs.NA', 'physics.chem-ph', 'cs.DB', 'q-bio.BM', 'cs.PL', 'cs.LO', 'cond-mat.dis-nn', '68T45', 'math.PR', 'physics.comp-ph', 'cs.CE', 'cs.AR', 'I.2.10', 'q-fin.ST', 'cond-mat.stat-mech', 'quant-ph', 'math.DS', '68T05', 'physics.data-an', 'cs.CC', 'I.4.6', 'physics.soc-ph', 'physics.ao-ph', 'econ.EM', 'cs.DM', 'q-bio.GN', 'physics.med-ph', 'astro-ph.IM', 'I.4.8', 'math.AT', 'cs.PF', 'I.4', 'q-fin.TR', 'cs.FL', 'I.5.4', 'I.2', '68U10', 'physics.optics', 'hep-ex', '68T10', 'physics.geo-ph', 'cond-mat.mtrl-sci', 'q-fin.CP', 'physics.flu-dyn', 'math.CO', 'math.AP', 'I.4; I.5', 'I.4.9', 'I.2.6; I.2.8', '68T01', '65D19', 'nlin.CD', 'cs.MS', 'I.2.6; I.5.1', 'I.2.10; I.4; I.5', 'I.2.0; I.2.6', '68T07', 'q-fin.GN', 'cs.SC', 'cs.ET', 'K.3.2', 'I.2; I.5', 'I.2.8', 'I.2.10; I.4.8', '68U01', '68T30', '68', 'q-fin.EC', 'q-bio.MN', 'econ.GN', 'I.4.9; I.5.4', 'I.4.5', 'I.2; I.4; I.5', 'I.2.6; I.2.7', '68T99', '68Q32', '62H30', 'q-fin.RM', 'q-fin.PM', 'q-bio.TO', 'q-bio.OT', 'physics.bio-ph', 'nlin.AO', 'math.LO', 'math.FA', 'hep-ph', 'cond-mat.soft', 'I.4.6; I.4.8', 'I.4.4', 'I.4.3', 'I.4.0', 'I.2; J.2', 'I.2; I.2.6; I.2.7', 'I.2.7', 'I.2.6; I.5.4', 'I.2.6; I.2.9', 'I.2.6; I.2.7; H.3.1; H.3.3', 'I.2.6; I.2.10', 'I.2.6, I.5.4', 'I.2.1; J.3', 'I.2.10; I.5.1; I.4.8', 'I.2.10; I.4.8; I.5.4', 'I.2.10; I.2.6', 'I.2.1', 'H.3.1; I.2.6; I.2.7', 'H.3.1; H.3.3; I.2.6; I.2.7', 'G.3', 'F.2.2; I.2.7', 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3', '68Txx', '62H99', '62H35', '14J60 (Primary) 14F05, 14J26 (Secondary)']\n"
     ]
    }
   ],
   "source": [
    "# Vectorization of the multi label binarization \n",
    "terms = tf.ragged.constant(train_df[\"terms\"].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
    "lookup.adapt(terms)\n",
    "vocab = lookup.get_vocabulary()\n",
    "\n",
    "\n",
    "def invert_multi_hot(encoded_labels):\n",
    "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
    "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
    "    return np.take(vocab, hot_indices)\n",
    "\n",
    "\n",
    "print(\"Vocabulary:\\n\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d18408e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs.LG', 'stat.ML']\n",
      "Original label: ['cs.LG', 'stat.ML']\n",
      "Label-binarized representation: [[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Binarization \n",
    "sample_label = train_df[\"terms\"].iloc[0]\n",
    "print(f\"Original label: {sample_label}\")\n",
    "\n",
    "label_binarized = lookup([sample_label])\n",
    "print(f\"Label-binarized representation: {label_binarized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92eaa58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More preprocessing\n",
    "train_df[\"summaries\"].apply(lambda x: len(x.split(\" \"))).describe()\n",
    "\n",
    "max_seqlen = 160\n",
    "batch_size = 128\n",
    "padding_token = \"<pad>\"\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"summaries\"].values, label_binarized)\n",
    "    )\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fcc74c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: b'Research in machine learning, mobile robotics, and autonomous driving is\\naccelerated by the availability of high quality annotated data. To this end, we\\nrelease the Audi Autonomous Driving Dataset (A2D2). Our dataset consists of\\nsimultaneously recorded images and 3D point clouds, together with 3D bounding\\nboxes, semantic segmentation, instance segmentation, and data extracted from\\nthe automotive bus. Our sensor suite consists of six cameras and five LiDAR\\nunits, providing full 360 degree coverage. The recorded data is time\\nsynchronized and mutually registered. Annotations are for non-sequential\\nframes: 41,277 frames with semantic segmentation image and point cloud labels,\\nof which 12,497 frames also have 3D bounding box annotations for objects within\\nthe field of view of the front camera. In addition, we provide 392,556\\nsequential frames of unannotated sensor data for recordings in three cities in\\nthe south of Germany. These sequences contain several loops. Faces and vehicle\\nnumber plates are blurred due to GDPR legislation and to preserve anonymity.\\nA2D2 is made available under the CC BY-ND 4.0 license, permitting commercial\\nuse subject to the terms of the license. Data and further information are\\navailable at http://www.a2d2.audi.'\n",
      "Label(s): ['cs.CV' 'cs.LG' 'eess.IV']\n",
      " \n",
      "Abstract: b\"Generative adversarial networks (GANs) are well known for their unsupervised\\nlearning capabilities. A recent success in the field of astronomy is deblending\\ntwo overlapping galaxy images via a branched GAN model. However, it remains a\\nsignificant challenge to comprehend how the network works, which is\\nparticularly difficult for non-expert users. This research focuses on behaviors\\nof one of the network's major components, the Discriminator, which plays a\\nvital role but is often overlooked, Specifically, we enhance the Layer-wise\\nRelevance Propagation (LRP) scheme to generate a heatmap-based visualization.\\nWe call this technique Polarized-LRP and it consists of two parts i.e. positive\\ncontribution heatmaps for ground truth images and negative contribution\\nheatmaps for generated images. Using the Galaxy Zoo dataset we demonstrate that\\nour method clearly reveals attention areas of the Discriminator when\\ndifferentiating generated galaxy images from ground truth images. To connect\\nthe Discriminator's impact on the Generator, we visualize the gradual changes\\nof the Generator across the training process. An interesting result we have\\nachieved there is the detection of a problematic data augmentation procedure\\nthat would else have remained hidden. We find that our proposed method serves\\nas a useful visual analytical tool for a deeper understanding of GAN models.\"\n",
      "Label(s): ['cs.CV' 'eess.IV']\n",
      " \n",
      "Abstract: b'We develop a probabilistic interpretation of two-stage object detection. We\\nshow that this probabilistic interpretation motivates a number of common\\nempirical training practices. It also suggests changes to two-stage detection\\npipelines. Specifically, the first stage should infer proper\\nobject-vs-background likelihoods, which should then inform the overall score of\\nthe detector. A standard region proposal network (RPN) cannot infer this\\nlikelihood sufficiently well, but many one-stage detectors can. We show how to\\nbuild a probabilistic two-stage detector from any state-of-the-art one-stage\\ndetector. The resulting detectors are faster and more accurate than both their\\none- and two-stage precursors. Our detector achieves 56.4 mAP on COCO test-dev\\nwith single-scale testing, outperforming all published results. Using a\\nlightweight backbone, our detector achieves 49.2 mAP on COCO at 33 fps on a\\nTitan Xp, outperforming the popular YOLOv4 model.'\n",
      "Label(s): ['cs.CV']\n",
      " \n",
      "Abstract: b'We study the off-policy evaluation (OPE) problem in reinforcement learning\\nwith linear function approximation, which aims to estimate the value function\\nof a target policy based on the offline data collected by a behavior policy. We\\npropose to incorporate the variance information of the value function to\\nimprove the sample efficiency of OPE. More specifically, for time-inhomogeneous\\nepisodic linear Markov decision processes (MDPs), we propose an algorithm,\\nVA-OPE, which uses the estimated variance of the value function to reweight the\\nBellman residual in Fitted Q-Iteration. We show that our algorithm achieves a\\ntighter error bound than the best-known result. We also provide a fine-grained\\ncharacterization of the distribution shift between the behavior policy and the\\ntarget policy. Extensive numerical experiments corroborate our theory.'\n",
      "Label(s): ['cs.LG' 'stat.ML' 'math.OC']\n",
      " \n",
      "Abstract: b'Image Segmentation plays an essential role in computer vision and image\\nprocessing with various applications from medical diagnosis to autonomous car\\ndriving. A lot of segmentation algorithms have been proposed for addressing\\nspecific problems. In recent years, the success of deep learning techniques has\\ntremendously influenced a wide range of computer vision areas, and the modern\\napproaches of image segmentation based on deep learning are becoming prevalent.\\nIn this article, we introduce a high-efficient development toolkit for image\\nsegmentation, named PaddleSeg. The toolkit aims to help both developers and\\nresearchers in the whole process of designing segmentation models, training\\nmodels, optimizing performance and inference speed, and deploying models.\\nCurrently, PaddleSeg supports around 20 popular segmentation models and more\\nthan 50 pre-trained models from real-time and high-accuracy levels. With\\nmodular components and backbone networks, users can easily build over one\\nhundred models for different requirements. Furthermore, we provide\\ncomprehensive benchmarks and evaluations to show that these segmentation\\nalgorithms trained on our toolkit have more competitive accuracy. Also, we\\nprovide various real industrial applications and practical cases based on\\nPaddleSeg. All codes and examples of PaddleSeg are available at\\nhttps://github.com/PaddlePaddle/PaddleSeg.'\n",
      "Label(s): ['cs.CV']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# preview dataset\n",
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "848fdf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153341\n"
     ]
    }
   ],
   "source": [
    "# Vectorization\n",
    "# Source: https://stackoverflow.com/a/18937309/7636462\n",
    "vocabulary = set()\n",
    "train_df[\"summaries\"].str.lower().str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)\n",
    "\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
    ")\n",
    "\n",
    "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
    "# training set.\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d01853cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(512, activation=\"relu\"),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "        ]  # More on why \"sigmoid\" has been used here in a moment.\n",
    "    )\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5544e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 56s 213ms/step - loss: 0.0321 - categorical_accuracy: 0.8534 - val_loss: 0.0182 - val_categorical_accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train \n",
    "epochs = 1\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "history = shallow_mlp_model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f70631bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 70ms/step - loss: 0.0186 - categorical_accuracy: 0.8898\n",
      "Categorical accuracy on the test set: 88.98%.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "_, categorical_acc = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Categorical accuracy on the test set: {round(categorical_acc * 100, 2)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da3f3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: b'Machine learning classifiers are often trained to recognize a set of\\npre-defined classes. However, in many applications, it is often desirable to\\nhave the flexibility of learning additional concepts, with limited data and\\nwithout re-training on the full training set. This paper addresses this\\nproblem, incremental few-shot learning, where a regular classification network\\nhas already been trained to recognize a set of base classes, and several extra\\nnovel classes are being considered, each with only a few labeled examples.\\nAfter learning the novel classes, the model is then evaluated on the overall\\nclassification performance on both base and novel classes. To this end, we\\npropose a meta-learning model, the Attention Attractor Network, which\\nregularizes the learning of novel classes. In each episode, we train a set of\\nnew weights to recognize novel classes until they converge, and we show that\\nthe technique of recurrent back-propagation can back-propagate through the\\noptimization process and facilitate the learning of these parameters. We\\ndemonstrate that the learned attractor network can help recognize novel classes\\nwhile remembering old classes without the need to review the original training\\nset, outperforming various baselines.'\n",
      "Label(s): ['cs.CV' 'cs.LG' 'stat.ML']\n",
      "Predicted Label(s): (cs.CV, cs.LG, stat.ML)\n",
      " \n",
      "Abstract: b'We propose a novel reinforcement learning-based approach for adaptive and\\niterative feature selection. Given a masked vector of input features, a\\nreinforcement learning agent iteratively selects certain features to be\\nunmasked, and uses them to predict an outcome when it is sufficiently\\nconfident. The algorithm makes use of a novel environment setting,\\ncorresponding to a non-stationary Markov Decision Process. A key component of\\nour approach is a guesser network, trained to predict the outcome from the\\nselected features and parametrizing the reward function. Applying our method to\\na national survey dataset, we show that it not only outperforms strong\\nbaselines when requiring the prediction to be made based on a small number of\\ninput features, but is also highly more interpretable. Our code is publicly\\navailable at \\\\url{https://github.com/ushaham/adaptiveFS}.'\n",
      "Label(s): ['cs.LG' 'stat.ML' 'cs.AI']\n",
      "Predicted Label(s): (cs.LG, stat.ML, cs.AI)\n",
      " \n",
      "Abstract: b'In recent years, cross-spectral iris recognition has emerged as a promising\\nbiometric approach to establish the identity of individuals. However, matching\\niris images acquired at different spectral bands (i.e., matching a visible\\n(VIS) iris probe to a gallery of near-infrared (NIR) iris images or vice versa)\\nshows a significant performance degradation when compared to intraband NIR\\nmatching. Hence, in this paper, we have investigated a range of deep\\nconvolutional generative adversarial network (DCGAN) architectures to further\\nimprove the accuracy of cross-spectral iris recognition methods. Moreover,\\nunlike the existing works in the literature, we introduce a resolution\\ndifference into the classical cross-spectral matching problem domain. We have\\ndeveloped two different techniques using the conditional generative adversarial\\nnetwork (cGAN) as a backbone architecture for cross-spectral iris matching. In\\nthe first approach, we simultaneously address the cross-resolution and\\ncross-spectral matching problem by training a cGAN that jointly translates\\ncross-resolution as well as cross-spectral tasks to the same resolution and\\nwithin the same spectrum. In the second approach, we design a coupled\\ngenerative adversarial network (cpGAN) architecture consisting of a pair of\\ncGAN modules that project the VIS and NIR iris images into a low-dimensional\\nembedding domain to ensure maximum pairwise similarity between the feature\\nvectors from the two iris modalities of the same subject.'\n",
      "Label(s): ['cs.CV']\n",
      "Predicted Label(s): (cs.CV, cs.LG, eess.IV)\n",
      " \n",
      "Abstract: b'As machine learning algorithms continue to improve, there is an increasing\\nneed for explaining why a model produces a certain prediction for a certain\\ninput. In recent years, several methods for model interpretability have been\\ndeveloped, aiming to provide explanation of which subset regions of the model\\ninput is the main reason for the model prediction. In parallel, a significant\\nresearch community effort is occurring in recent years for developing\\nadversarial example generation methods for fooling models, while not altering\\nthe true label of the input,as it would have been classified by a human\\nannotator. In this paper, we bridge the gap between adversarial example\\ngeneration and model interpretability, and introduce a modification to the\\nadversarial example generation process which encourages better\\ninterpretability. We analyze the proposed method on a public medical imaging\\ndataset, both quantitatively and qualitatively, and show that it significantly\\noutperforms the leading known alternative method. Our suggested method is\\nsimple to implement, and can be easily plugged into most common adversarial\\nexample generation frameworks. Additionally, we propose an explanation quality\\nmetric - $APE$ - \"Adversarial Perturbative Explanation\", which measures how\\nwell an explanation describes model decisions.'\n",
      "Label(s): ['cs.CV' 'cs.LG' 'stat.ML' 'cs.CR']\n",
      "Predicted Label(s): (cs.LG, cs.CV, stat.ML)\n",
      " \n",
      "Abstract: b'Estimating the remaining surgery duration (RSD) during surgical procedures\\ncan be useful for OR planning and anesthesia dose estimation. With the recent\\nsuccess of deep learning-based methods in computer vision, several neural\\nnetwork approaches have been proposed for fully automatic RSD prediction based\\nsolely on visual data from the endoscopic camera. We investigate whether RSD\\nprediction can be improved using unsupervised temporal video segmentation as an\\nauxiliary learning task. As opposed to previous work, which presented\\nsupervised surgical phase recognition as auxiliary task, we avoid the need for\\nmanual annotations by proposing a similar but unsupervised learning objective\\nwhich clusters video sequences into temporally coherent segments. In multiple\\nexperimental setups, results obtained by learning the auxiliary task are\\nincorporated into a deep RSD model through feature extraction, pretraining or\\nregularization. Further, we propose a novel loss function for RSD training\\nwhich attempts to counteract unfavorable characteristics of the RSD ground\\ntruth. Using our unsupervised method as an auxiliary task for RSD training, we\\noutperform other self-supervised methods and are comparable to the supervised\\nstate-of-the-art. Combined with the novel RSD loss, we slightly outperform the\\nsupervised approach.'\n",
      "Label(s): ['cs.CV']\n",
      "Predicted Label(s): (cs.CV, cs.LG, stat.ML)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# End to End model \n",
    "model_for_inference = keras.Sequential([text_vectorizer, shallow_mlp_model])\n",
    "\n",
    "# Create a small dataset just for demoing inference.\n",
    "inference_dataset = make_dataset(test_df.sample(100), is_train=False)\n",
    "text_batch, label_batch = next(iter(inference_dataset))\n",
    "predicted_probabilities = model_for_inference.predict(text_batch)\n",
    "\n",
    "# Perform inference.\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    predicted_proba = [proba for proba in predicted_probabilities[i]]\n",
    "    top_3_labels = [\n",
    "        x\n",
    "        for _, x in sorted(\n",
    "            zip(predicted_probabilities[i], lookup.get_vocabulary()),\n",
    "            key=lambda pair: pair[0],\n",
    "            reverse=True,\n",
    "        )\n",
    "    ][:3]\n",
    "    print(f\"Predicted Label(s): ({', '.join([label for label in top_3_labels])})\")\n",
    "    print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
