{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc0b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302d5144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Training device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f390cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=300, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=300, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209e6ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4])\n"
     ]
    }
   ],
   "source": [
    "# Get initial prediction \n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X) # Get logits from model (predictions)\n",
    "pred_probab = nn.Softmax(dim=1)(logits) # get probability \n",
    "y_pred = pred_probab.argmax(1) # Find predicted class \n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e7a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# minibatch of size 3 \n",
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2f5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# Flatten \n",
    "flatten = nn.Flatten() # flatten layer \n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244f95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# Linear transform \n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ddd9112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-3.3560e-01, -4.5919e-01,  2.4642e-01, -3.3313e-01, -5.2785e-02,\n",
      "         -6.9358e-01,  2.4218e-01,  2.6250e-01,  1.8091e-01,  2.6777e-01,\n",
      "          1.0016e-01,  3.4641e-01,  2.0225e-01,  2.2813e-01, -1.4953e-01,\n",
      "          2.6209e-01, -1.0052e-01,  1.3246e-03,  1.4766e-01,  1.4833e-01],\n",
      "        [-3.3730e-01, -1.0123e-01,  2.1543e-01, -1.3996e-01,  3.9756e-02,\n",
      "         -4.0434e-01,  9.2186e-02,  1.6282e-01,  8.7210e-03, -3.1627e-01,\n",
      "         -4.5786e-01,  4.0195e-01,  1.0305e-01, -6.7269e-02, -2.4217e-01,\n",
      "          1.6081e-01, -3.3481e-01,  2.0169e-02,  4.9292e-01,  4.2445e-04],\n",
      "        [-3.8932e-01, -3.2384e-01,  1.0678e-01,  2.2381e-01, -2.7386e-01,\n",
      "         -7.2335e-01,  2.6898e-01,  1.9139e-01,  1.4466e-01, -2.0953e-01,\n",
      "         -4.9018e-01,  3.2371e-01,  1.6510e-01, -8.0963e-02, -2.7826e-04,\n",
      "          7.2788e-02,  1.7909e-02,  1.5802e-01,  4.6243e-01, -1.2237e-01]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000e+00, 0.0000e+00, 2.4642e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.4218e-01, 2.6250e-01, 1.8091e-01, 2.6777e-01, 1.0016e-01, 3.4641e-01,\n",
      "         2.0225e-01, 2.2813e-01, 0.0000e+00, 2.6209e-01, 0.0000e+00, 1.3246e-03,\n",
      "         1.4766e-01, 1.4833e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 2.1543e-01, 0.0000e+00, 3.9756e-02, 0.0000e+00,\n",
      "         9.2186e-02, 1.6282e-01, 8.7210e-03, 0.0000e+00, 0.0000e+00, 4.0195e-01,\n",
      "         1.0305e-01, 0.0000e+00, 0.0000e+00, 1.6081e-01, 0.0000e+00, 2.0169e-02,\n",
      "         4.9292e-01, 4.2445e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0678e-01, 2.2381e-01, 0.0000e+00, 0.0000e+00,\n",
      "         2.6898e-01, 1.9139e-01, 1.4466e-01, 0.0000e+00, 0.0000e+00, 3.2371e-01,\n",
      "         1.6510e-01, 0.0000e+00, 0.0000e+00, 7.2788e-02, 1.7909e-02, 1.5802e-01,\n",
      "         4.6243e-01, 0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# non linear activation (ReLU)\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c9dda92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 2, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0857, 0.1043, 0.1170, 0.0898, 0.0826, 0.0969, 0.0705, 0.1154, 0.1067,\n",
       "         0.1312],\n",
       "        [0.0804, 0.1010, 0.1305, 0.0910, 0.0733, 0.1067, 0.0692, 0.1110, 0.1074,\n",
       "         0.1297],\n",
       "        [0.0814, 0.1027, 0.1206, 0.0924, 0.0841, 0.0979, 0.0772, 0.1124, 0.0978,\n",
       "         0.1335]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn sequential \n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10) # get output \n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits.shape\n",
    "\n",
    "# Get predictions \n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab.argmax(axis=1)) # get max \n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97e1fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=300, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=300, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([500, 784]) | Values : tensor([[-0.0279, -0.0203,  0.0219,  ..., -0.0296, -0.0075,  0.0299],\n",
      "        [-0.0202,  0.0265,  0.0120,  ...,  0.0264, -0.0243, -0.0018]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([500]) | Values : tensor([0.0298, 0.0253], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([300, 500]) | Values : tensor([[ 1.9436e-03,  7.3831e-03, -2.5742e-02,  3.4341e-02,  2.8283e-02,\n",
      "          3.0806e-02,  2.1972e-02,  3.8721e-02,  3.5151e-02, -2.3217e-02,\n",
      "         -2.4017e-02,  1.5989e-03,  2.8442e-02,  2.7545e-02,  1.2138e-02,\n",
      "         -1.4362e-02, -3.7137e-02,  3.3010e-02, -3.0023e-02, -3.6355e-03,\n",
      "          5.4796e-03,  3.3535e-02,  2.5586e-02, -2.6923e-02,  3.3065e-02,\n",
      "          1.4223e-02,  1.0545e-02,  1.7044e-02,  1.8598e-03, -6.9603e-03,\n",
      "          7.9687e-03,  3.1338e-02,  3.2826e-02,  7.4722e-03,  3.2608e-02,\n",
      "         -8.3692e-03, -1.3897e-02,  1.8441e-02, -3.9518e-02, -2.8398e-02,\n",
      "         -3.2966e-03,  3.3059e-02,  3.6953e-02, -3.0066e-02,  1.7467e-02,\n",
      "         -2.5917e-02,  2.4490e-03, -2.5686e-02, -2.8643e-02, -2.3352e-02,\n",
      "         -3.6184e-02,  1.6323e-02, -3.3887e-02, -2.2019e-02, -1.5061e-02,\n",
      "         -3.3887e-02, -3.2276e-02,  2.9390e-02,  2.9639e-02, -1.7382e-02,\n",
      "          1.4788e-02,  4.4087e-02,  3.0304e-03, -8.7572e-03, -3.4250e-02,\n",
      "          1.2858e-02, -2.9452e-02,  4.1957e-02, -8.5943e-03, -1.3043e-02,\n",
      "          3.8660e-02, -8.9628e-03,  3.9990e-02,  1.5753e-02, -1.3955e-03,\n",
      "          6.7399e-03, -3.6901e-03,  3.7217e-02, -3.2525e-03,  5.9372e-03,\n",
      "          3.0708e-02, -3.3781e-02,  3.9273e-02,  4.4963e-03,  3.9244e-02,\n",
      "          2.5081e-02,  1.3414e-02, -3.5760e-02, -1.8869e-02, -7.4909e-03,\n",
      "         -4.3679e-02, -1.4005e-02,  4.4543e-02,  1.7139e-02,  2.1447e-02,\n",
      "         -1.9440e-02, -1.0547e-04,  2.0556e-02,  1.7850e-02,  2.6818e-02,\n",
      "          1.4536e-02, -1.5105e-02, -3.4967e-02, -2.5063e-03,  3.8085e-02,\n",
      "          2.6230e-02, -4.2755e-02, -3.9248e-02,  5.4219e-03,  1.4791e-02,\n",
      "          1.9381e-02,  1.2822e-03, -1.1345e-02, -3.2834e-02,  4.2184e-02,\n",
      "         -8.7208e-03,  1.7463e-02,  3.2475e-02, -2.8255e-02,  3.5124e-02,\n",
      "         -1.5884e-02,  1.7429e-02, -4.2198e-02,  1.4134e-02, -3.4075e-03,\n",
      "         -2.0481e-02, -3.0983e-02,  1.0255e-02,  3.6842e-02, -1.7130e-02,\n",
      "          2.1578e-02,  2.4677e-02,  9.8349e-03, -2.0497e-02,  1.5570e-02,\n",
      "         -1.1145e-02, -1.1538e-03,  4.1415e-02, -2.2592e-02,  7.2046e-03,\n",
      "          4.1345e-02, -1.0001e-02, -1.7767e-03, -5.3183e-04,  1.7002e-03,\n",
      "          4.2638e-02,  8.2982e-04,  1.4730e-03, -2.0562e-02, -4.1331e-02,\n",
      "          2.1080e-02, -2.1251e-02, -1.8592e-02,  3.0880e-02,  3.5939e-02,\n",
      "          3.4431e-02, -2.3754e-02, -4.1017e-02,  2.9284e-02,  3.8112e-02,\n",
      "          1.1201e-02,  4.9102e-03, -4.4568e-02, -1.6284e-02, -3.6604e-02,\n",
      "          1.6774e-02, -2.0279e-02, -3.6252e-02,  4.2114e-02,  2.5643e-02,\n",
      "         -1.4013e-02,  4.2470e-02,  1.8452e-02, -1.3555e-02, -1.7732e-02,\n",
      "         -3.3122e-02, -7.7544e-03, -7.3443e-03, -1.4033e-02,  2.2745e-02,\n",
      "         -8.8947e-03, -1.9828e-02,  8.8077e-03, -1.4124e-02, -2.2792e-02,\n",
      "          3.9092e-02, -2.4759e-02,  3.2379e-03,  2.5887e-02,  1.8368e-02,\n",
      "         -5.7499e-03, -4.7165e-03,  3.5064e-02, -2.1556e-02,  3.2175e-02,\n",
      "         -2.3945e-02, -3.0659e-02, -3.3654e-02, -2.0781e-02,  4.1568e-02,\n",
      "          2.4738e-02,  4.2040e-02, -4.4500e-02, -2.5039e-02, -2.9120e-02,\n",
      "         -6.5907e-03, -5.6785e-03,  5.1936e-03,  2.2022e-02,  2.4977e-02,\n",
      "         -3.8146e-02,  2.6947e-02,  2.9234e-02, -8.3330e-03, -5.5552e-03,\n",
      "          3.0456e-02, -3.1052e-02, -2.7331e-03,  2.2505e-02,  3.2976e-02,\n",
      "         -4.4332e-03,  2.4586e-03,  1.3059e-02,  1.0482e-02,  9.0398e-03,\n",
      "         -2.0466e-02, -2.1974e-02,  6.4579e-03, -1.5315e-03, -2.3972e-02,\n",
      "         -5.7793e-03, -2.5717e-02, -9.2981e-03,  1.6752e-02, -6.7218e-03,\n",
      "          4.1192e-02,  4.0638e-02,  2.3650e-02, -3.1808e-02,  2.5840e-02,\n",
      "         -1.6999e-02, -6.4495e-03, -6.4087e-03, -2.5472e-02,  7.3265e-03,\n",
      "         -3.8018e-02, -4.0130e-02, -6.9555e-03,  5.5228e-03,  1.8743e-02,\n",
      "         -1.0026e-02, -1.7640e-02, -7.6554e-03, -2.2879e-02, -1.5570e-02,\n",
      "          8.8841e-03, -4.5159e-03, -1.7811e-02, -2.7116e-02,  3.8626e-02,\n",
      "         -1.4977e-02,  1.6770e-02, -2.3286e-02,  1.4210e-02,  3.6670e-02,\n",
      "          4.2178e-03,  1.5988e-02, -1.6357e-04, -3.0449e-02,  4.0283e-02,\n",
      "          6.5909e-03, -3.3897e-02, -4.1354e-02,  4.3813e-02,  4.2276e-02,\n",
      "          6.0354e-03, -2.7127e-02,  3.2970e-02, -3.5311e-02,  1.1607e-02,\n",
      "          2.7325e-03,  2.9573e-03, -2.2000e-02, -3.3121e-02, -1.3350e-03,\n",
      "          3.0513e-02,  1.7076e-02, -2.6030e-02, -2.3334e-02, -3.7449e-02,\n",
      "         -1.7379e-02, -5.4730e-03,  1.3495e-02,  1.7988e-02,  2.5848e-02,\n",
      "          3.3776e-02,  3.7739e-02, -7.8565e-03,  1.8548e-02, -3.3839e-02,\n",
      "          4.1578e-02, -3.1714e-02, -8.5870e-03,  9.6391e-03,  4.2150e-02,\n",
      "         -2.0772e-02, -2.3079e-02, -3.1412e-02,  1.7117e-02,  2.6597e-02,\n",
      "          3.3543e-02, -2.8804e-02,  3.6978e-02, -1.2517e-02,  1.3031e-02,\n",
      "         -3.7194e-02, -2.5159e-02,  1.1529e-03, -3.6909e-02, -1.4846e-02,\n",
      "         -1.8350e-03,  1.8576e-02,  4.2534e-02,  3.6390e-02, -9.5324e-03,\n",
      "         -2.0638e-02, -3.6805e-02,  4.2355e-02, -2.3585e-02, -4.0602e-02,\n",
      "         -4.7888e-03,  2.6868e-02, -3.2829e-02,  4.1147e-02,  2.3310e-02,\n",
      "          3.1138e-02, -4.1961e-02,  2.4503e-02,  2.9066e-02, -1.0186e-02,\n",
      "          1.5109e-03, -9.6115e-03, -3.3109e-02, -3.3555e-02,  1.7050e-02,\n",
      "          1.4976e-02,  3.8553e-02, -3.4725e-02, -1.8897e-03,  2.4881e-02,\n",
      "         -2.1555e-02,  4.3368e-03, -2.2834e-02, -3.2485e-02, -1.6923e-02,\n",
      "          5.9143e-03, -4.2333e-02, -3.4701e-02, -3.0989e-02, -1.6216e-03,\n",
      "          2.5734e-02, -4.1025e-02,  3.5939e-02,  5.6392e-03,  1.5674e-02,\n",
      "          4.0613e-02,  5.3493e-03, -2.1136e-02, -9.5405e-03, -7.2370e-04,\n",
      "          2.0703e-02, -3.6820e-03, -2.7322e-02,  3.1078e-02, -2.1949e-02,\n",
      "          1.7244e-02, -1.1193e-02, -3.6545e-03, -3.6819e-02, -3.7449e-02,\n",
      "          3.6362e-02, -3.8697e-02, -7.3914e-03, -3.0491e-02, -2.8597e-02,\n",
      "          2.7209e-02,  2.8006e-02, -8.6670e-03, -3.1201e-02,  6.9161e-03,\n",
      "         -4.1903e-02,  3.5631e-02, -3.5379e-02, -3.3836e-02,  3.4090e-02,\n",
      "         -7.2893e-03, -2.3142e-02, -3.1737e-02,  4.1860e-02,  4.2073e-02,\n",
      "         -1.8301e-02,  2.6234e-02,  1.7629e-02,  3.6878e-02, -2.6517e-02,\n",
      "         -3.8036e-02,  4.0779e-02,  1.6339e-02, -1.5221e-02, -8.3475e-03,\n",
      "         -3.3678e-02,  1.8936e-03, -3.4938e-02,  8.3680e-03, -3.7285e-02,\n",
      "         -3.0111e-02,  3.2157e-02, -3.5462e-02, -2.7878e-02,  2.6539e-02,\n",
      "          2.3601e-02, -2.2858e-02, -4.4144e-02,  1.1152e-02, -1.2819e-02,\n",
      "         -2.7869e-02,  2.0754e-02, -2.2288e-02,  1.3830e-02,  3.2730e-02,\n",
      "          2.6631e-02,  1.5408e-02,  1.0559e-04,  1.1883e-02,  2.3482e-02,\n",
      "         -3.7815e-02,  3.8786e-02, -3.3432e-02,  5.3126e-03,  5.1851e-03,\n",
      "          1.9218e-02, -3.0141e-02, -3.2409e-02,  1.6074e-02, -1.0034e-02,\n",
      "          3.5231e-02, -2.2818e-02,  6.5738e-03, -4.1347e-03, -1.3538e-02,\n",
      "          4.3107e-02, -7.3597e-03,  3.6381e-02, -4.0817e-02,  1.6106e-02,\n",
      "          1.8247e-03, -2.5434e-02,  1.9434e-03,  2.0626e-02, -3.6762e-03,\n",
      "          3.6265e-02, -7.9713e-04, -7.4607e-03,  1.6439e-02,  2.3917e-02,\n",
      "          2.5148e-02, -3.4871e-02, -1.4363e-02,  1.0662e-02,  3.2415e-02,\n",
      "         -2.2888e-02, -3.5605e-02, -4.4431e-02,  2.5402e-02, -3.6034e-02,\n",
      "         -4.4102e-02,  2.0907e-02, -1.0026e-02, -2.3842e-02,  2.2463e-02,\n",
      "          8.5448e-03, -4.2339e-03, -3.3493e-02, -4.2993e-02,  1.6651e-02,\n",
      "         -8.3931e-03, -4.1422e-02,  2.3714e-02, -2.9118e-02,  8.5719e-03,\n",
      "          3.1787e-02,  1.3525e-02, -3.7291e-02, -2.8459e-02,  3.4142e-03,\n",
      "          2.9345e-02,  4.2116e-02,  4.0789e-02,  6.5479e-03, -3.9073e-04],\n",
      "        [ 2.4000e-02,  3.8838e-02, -2.5058e-02,  2.6753e-02,  2.8239e-02,\n",
      "         -6.5711e-03, -8.7509e-03,  1.9063e-02,  3.3106e-02, -3.8838e-02,\n",
      "          3.3401e-02,  6.7720e-03, -3.3246e-02, -4.3934e-02,  2.9400e-02,\n",
      "          8.4361e-03, -6.2860e-03, -2.5441e-02, -3.7265e-02, -3.3986e-02,\n",
      "         -2.0256e-02,  3.5100e-02,  3.0438e-03,  4.3918e-02,  4.2511e-02,\n",
      "         -3.5059e-02,  9.0548e-03,  2.8327e-02,  1.5453e-02,  4.2722e-02,\n",
      "         -1.3735e-02, -4.3727e-02, -1.5524e-02,  4.8623e-03, -4.0183e-02,\n",
      "         -2.2918e-02, -2.1646e-02,  4.4206e-02,  3.1860e-02, -1.7526e-04,\n",
      "          1.3084e-02,  7.4709e-04, -3.8855e-03,  4.3143e-03,  2.0424e-02,\n",
      "         -2.7135e-02,  1.9316e-02, -3.5644e-02, -2.3904e-02, -3.2588e-02,\n",
      "         -4.1961e-02,  2.6223e-02,  2.8334e-02, -4.2779e-02, -1.3512e-02,\n",
      "          1.5778e-02, -4.3195e-02,  3.7135e-02, -2.7170e-02, -1.0201e-02,\n",
      "          4.4659e-02, -3.5923e-04,  2.6063e-02, -1.8664e-03,  1.0049e-02,\n",
      "         -3.1803e-02, -5.5474e-03,  2.0359e-02, -5.4889e-03, -4.5401e-03,\n",
      "         -2.4612e-02,  1.2883e-02,  3.9724e-03, -3.7099e-02,  1.0549e-02,\n",
      "         -9.4037e-03, -3.6168e-02,  4.0610e-02,  1.3092e-02,  2.9541e-02,\n",
      "         -2.1495e-02,  4.2466e-02, -3.1232e-02,  3.7497e-04,  3.5807e-02,\n",
      "          2.0917e-02,  2.2355e-02, -2.5518e-02,  1.6657e-02,  3.1809e-02,\n",
      "          4.0817e-02, -2.8646e-02,  3.1899e-02, -2.8207e-02,  6.3987e-03,\n",
      "          4.1293e-02, -6.4595e-03, -4.2929e-02, -7.3846e-03, -4.2238e-02,\n",
      "         -3.2390e-03,  3.0805e-02, -3.4433e-03, -3.9323e-03,  3.2479e-02,\n",
      "         -3.7459e-02, -1.5596e-02, -5.6766e-03, -2.6187e-02, -1.8880e-02,\n",
      "         -4.3023e-02, -4.3141e-02,  3.8231e-02, -1.7117e-02,  3.0832e-02,\n",
      "          4.1429e-02, -2.7076e-02,  4.2710e-02,  2.5411e-02, -2.7769e-02,\n",
      "          3.9883e-02,  3.2008e-03,  2.5500e-02,  1.7518e-02,  8.1276e-03,\n",
      "          9.0107e-03, -2.2306e-02,  4.4419e-02,  3.7709e-04, -2.3311e-02,\n",
      "          1.5118e-02,  1.8867e-03,  4.4123e-03,  3.4172e-02,  3.4246e-02,\n",
      "          2.1219e-02, -4.3516e-02,  4.4136e-02, -2.9992e-02,  2.0862e-02,\n",
      "         -9.9044e-03,  3.1601e-02, -4.1249e-02, -1.0128e-02, -1.6993e-02,\n",
      "          1.0750e-02,  1.7881e-03, -1.8172e-02,  1.0613e-02, -8.4435e-03,\n",
      "          2.7084e-02, -4.1166e-02, -6.0400e-03, -3.9266e-02, -4.2877e-02,\n",
      "         -1.3663e-02,  3.5124e-03,  3.4878e-02, -1.0176e-02, -4.1715e-02,\n",
      "         -1.2125e-03, -4.0242e-02,  2.5880e-03, -5.6406e-03, -1.1501e-02,\n",
      "          3.8871e-02,  2.9777e-02, -6.9946e-05, -2.2491e-02,  3.6104e-02,\n",
      "          3.2940e-02,  1.8232e-02, -1.6454e-03,  2.9176e-03, -1.9244e-02,\n",
      "          2.5520e-03, -1.7423e-02, -2.6623e-02, -8.5340e-03,  1.1223e-02,\n",
      "          1.1973e-02, -5.9644e-03,  3.4150e-02,  3.1360e-02,  4.2997e-02,\n",
      "         -1.2237e-02, -4.4072e-02, -2.0385e-02,  2.0408e-03, -6.5595e-03,\n",
      "          3.4135e-02,  1.5160e-02,  2.1427e-02,  3.4533e-02, -1.4394e-02,\n",
      "         -3.0805e-02,  9.8595e-03,  5.7476e-03,  1.9806e-02,  4.2487e-02,\n",
      "         -3.6292e-02, -5.8647e-03,  4.5439e-03, -3.5333e-02,  4.1733e-03,\n",
      "         -1.2834e-02,  1.0520e-02,  2.7207e-03,  4.0988e-02, -1.3839e-02,\n",
      "          1.9833e-05, -3.5326e-02, -2.0595e-02, -1.2217e-02,  3.1862e-02,\n",
      "         -5.6087e-03, -2.8056e-02,  4.4222e-03, -3.1135e-02, -1.8971e-02,\n",
      "         -1.1076e-02,  6.9216e-04,  1.7835e-03, -1.2772e-02, -6.6968e-03,\n",
      "          3.5585e-02, -2.7997e-02, -2.8518e-02, -3.5931e-02,  4.0466e-02,\n",
      "         -1.3888e-02,  3.9129e-02,  2.2792e-02,  3.5371e-02,  5.8757e-03,\n",
      "         -1.5048e-02,  7.9967e-03, -2.6598e-02,  6.7849e-03, -3.0237e-02,\n",
      "         -4.8578e-03, -3.2557e-02,  2.1526e-02,  5.7038e-05,  3.9172e-02,\n",
      "         -3.6267e-02, -3.8098e-02, -1.3234e-02, -2.0047e-02,  2.8061e-02,\n",
      "         -2.5187e-02,  7.8164e-03, -2.8325e-02,  3.0966e-02, -5.5330e-03,\n",
      "          2.3430e-02, -3.0827e-02, -8.8690e-03,  4.0713e-02, -1.0663e-02,\n",
      "          3.7695e-02,  1.7699e-02,  2.4571e-02,  3.5151e-02,  1.8200e-02,\n",
      "          2.8425e-02, -2.0034e-02,  2.8127e-02, -4.2564e-02,  1.2399e-02,\n",
      "          1.8244e-02, -2.4242e-02, -2.5253e-02, -3.7365e-02, -4.7569e-03,\n",
      "         -6.2575e-03,  2.3800e-02,  3.2891e-02,  1.5581e-02,  2.9799e-02,\n",
      "         -5.8847e-03,  1.1585e-02,  4.3037e-02, -1.5435e-02, -4.2884e-02,\n",
      "          9.9007e-03,  3.3843e-02,  3.3093e-02,  1.5317e-02,  2.0709e-02,\n",
      "         -1.4124e-02,  3.9110e-02, -3.1726e-02,  3.6671e-02,  4.2056e-02,\n",
      "          1.0263e-03, -2.4029e-02,  4.4630e-02,  1.9054e-02, -2.2970e-03,\n",
      "          4.0652e-02,  1.1558e-02, -3.3103e-02,  3.9830e-04,  3.7716e-02,\n",
      "         -2.7010e-02,  1.2854e-02, -3.0689e-02, -2.8324e-03, -3.3188e-02,\n",
      "          4.1280e-02,  3.8646e-02, -1.8723e-02,  3.5260e-02,  1.3691e-02,\n",
      "          3.6860e-02, -2.0056e-02, -3.7915e-02,  4.1207e-02, -2.0422e-02,\n",
      "          1.4157e-02, -6.2443e-04, -2.1456e-02, -4.1835e-02, -2.5645e-02,\n",
      "         -4.4357e-02,  3.6124e-02,  8.5853e-04, -8.7329e-03,  2.1285e-02,\n",
      "          6.3677e-03,  3.3511e-02, -4.0495e-02, -1.0056e-02, -4.1734e-03,\n",
      "          3.3498e-02,  2.2944e-02, -1.0047e-02,  3.7463e-03,  2.3491e-02,\n",
      "          3.8549e-02,  3.7976e-02, -1.1448e-02,  3.4352e-02,  1.3590e-02,\n",
      "          2.1343e-02, -3.4843e-02,  1.0889e-02,  8.9922e-04,  3.4499e-03,\n",
      "          1.8178e-02, -2.8533e-02, -6.7770e-05,  1.0757e-02, -3.5593e-04,\n",
      "         -2.9124e-03, -2.9990e-02,  2.2678e-02,  1.2799e-02,  1.0143e-02,\n",
      "         -3.8743e-02,  4.5839e-03,  4.4547e-02,  1.2032e-02, -9.8908e-03,\n",
      "         -9.4976e-03,  3.6352e-02,  1.1584e-02, -1.3910e-05,  2.5996e-02,\n",
      "          3.8616e-02, -2.4963e-02,  1.7504e-02,  3.7665e-02,  2.1100e-02,\n",
      "          9.0369e-03,  2.1581e-02,  4.4504e-02,  3.3047e-02, -1.0088e-03,\n",
      "         -3.2686e-02, -2.7983e-02, -6.6900e-03, -1.9049e-02, -8.8716e-03,\n",
      "          3.5939e-02, -1.8520e-02, -3.1438e-02,  2.4760e-02,  3.3428e-02,\n",
      "         -1.1854e-02, -3.0445e-03, -5.2279e-04, -1.9954e-02, -3.9309e-02,\n",
      "         -2.4383e-02, -1.9467e-02, -6.2762e-03,  3.3737e-02,  5.2047e-03,\n",
      "          7.1850e-04, -4.0942e-02,  1.8073e-02, -3.0618e-02, -1.9581e-02,\n",
      "          2.8239e-03,  4.1387e-02, -1.1094e-02, -2.4665e-03,  4.2018e-02,\n",
      "          1.7081e-02,  1.8228e-02, -1.4522e-02, -3.1233e-02, -1.6853e-02,\n",
      "          3.1213e-02,  2.5334e-02, -1.4784e-02, -1.5200e-02, -2.2259e-02,\n",
      "         -3.8162e-02,  2.6660e-02,  2.5277e-02, -3.9847e-02,  1.8777e-02,\n",
      "          3.1190e-02,  8.2541e-03,  1.3325e-02,  4.3465e-02, -3.0775e-02,\n",
      "         -3.1585e-02,  3.1862e-02, -3.3027e-02, -3.9598e-02,  3.1673e-02,\n",
      "          1.4590e-02,  2.3529e-02, -3.7153e-02,  9.3246e-03, -1.7290e-02,\n",
      "          1.1838e-02,  2.5181e-02,  1.3348e-02,  3.4819e-02, -1.5198e-02,\n",
      "         -2.5526e-02,  2.2980e-02,  3.0337e-02,  2.5200e-02,  3.1971e-02,\n",
      "         -1.2456e-03,  3.6809e-02, -2.2167e-02, -1.4619e-03, -8.3197e-03,\n",
      "         -3.8291e-02,  3.7359e-02, -5.6773e-03, -7.5021e-03, -9.5313e-03,\n",
      "         -7.1546e-04,  3.7899e-02,  3.4208e-02,  1.5952e-02, -2.7796e-02,\n",
      "         -2.8039e-02, -4.0826e-03,  1.0929e-02,  3.7378e-02, -5.5815e-04,\n",
      "          4.0448e-02,  1.1926e-03,  1.2203e-02,  1.8245e-02,  3.4994e-02,\n",
      "          7.8403e-03,  3.4360e-02, -2.8103e-02, -2.1249e-02, -3.0228e-03,\n",
      "          1.6489e-03, -2.8601e-02, -3.7708e-03,  2.6042e-02, -3.4589e-03,\n",
      "          1.5204e-02,  2.4638e-02,  4.2013e-02,  3.1428e-02, -1.4320e-02,\n",
      "         -3.3688e-02,  2.1764e-02,  2.5632e-02, -9.0212e-03,  4.2806e-02,\n",
      "          3.7298e-02,  3.7987e-02, -1.9357e-02,  3.5323e-02,  3.1688e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([300]) | Values : tensor([0.0217, 0.0416], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 300]) | Values : tensor([[ 3.9537e-02, -4.8969e-02,  4.9369e-02, -3.3470e-03, -5.2937e-02,\n",
      "          3.0422e-02,  3.2126e-02, -3.5292e-02, -2.8266e-02, -3.8798e-02,\n",
      "          1.0273e-02, -1.6069e-02,  1.5563e-02,  1.1109e-02,  4.4118e-02,\n",
      "         -2.4459e-02,  2.7047e-02, -3.3907e-02, -5.1537e-02,  6.1529e-03,\n",
      "          1.9336e-02,  5.6847e-02,  4.2650e-02,  8.4882e-03, -2.3603e-03,\n",
      "         -2.9539e-03,  1.8423e-02,  4.5760e-02, -9.9153e-03, -7.5445e-03,\n",
      "          1.9317e-02, -4.0507e-02, -3.5894e-02,  2.0187e-02,  3.8060e-02,\n",
      "          4.3953e-02, -1.1138e-02,  4.6702e-03, -1.8492e-02,  2.5041e-02,\n",
      "          3.0370e-02,  2.0543e-02, -9.2934e-04, -8.5275e-03,  2.0307e-02,\n",
      "          2.4938e-02,  2.1983e-02,  3.4022e-02, -3.8203e-02, -4.4152e-02,\n",
      "          1.2578e-02, -5.0952e-02,  9.6038e-04,  5.6711e-02,  5.6633e-02,\n",
      "         -3.3151e-02, -1.7423e-02, -3.1673e-02,  3.4548e-02, -4.1547e-02,\n",
      "         -2.2729e-02, -3.7343e-02, -9.8240e-03,  3.5782e-02, -1.7827e-02,\n",
      "          5.3875e-02,  2.5706e-02,  5.4718e-02, -1.3769e-02,  1.7204e-02,\n",
      "          4.6490e-02, -5.5183e-02,  4.4459e-02, -2.4729e-02, -4.7609e-02,\n",
      "          1.4694e-02, -2.0269e-03, -3.9558e-02,  4.0655e-02, -3.6993e-02,\n",
      "         -1.5707e-02, -2.5618e-02, -5.0320e-02, -1.1062e-02,  5.2537e-02,\n",
      "          7.3369e-03,  2.7505e-02, -1.0755e-02,  4.0271e-02,  1.7419e-02,\n",
      "         -5.5255e-02, -5.7240e-02, -2.3310e-02,  2.5654e-02,  3.6196e-02,\n",
      "          4.9665e-02, -2.4310e-02, -4.4038e-02,  2.3452e-02, -1.3658e-02,\n",
      "          1.2543e-02,  4.4393e-02, -4.7027e-02, -5.1977e-02,  2.6189e-02,\n",
      "         -4.8300e-02, -1.7586e-02, -1.1065e-02,  2.2868e-03, -1.5872e-02,\n",
      "          1.0366e-04,  5.7703e-02,  3.7503e-02,  2.6618e-02,  5.5390e-02,\n",
      "         -4.3118e-02, -4.6898e-02, -1.1266e-03, -1.6667e-02, -2.9151e-03,\n",
      "         -5.4872e-02, -2.3975e-02,  4.8530e-02,  3.9945e-02, -1.0585e-02,\n",
      "         -2.2955e-02,  3.3343e-02,  1.3862e-02,  2.7440e-02, -1.3180e-02,\n",
      "          2.1192e-02,  2.0798e-02,  5.5711e-02,  3.4605e-02, -4.2505e-02,\n",
      "          4.2024e-02,  3.9560e-02, -2.4110e-02, -3.9504e-02, -1.1216e-02,\n",
      "          1.6625e-02, -3.0847e-02,  4.0780e-02, -5.1751e-03,  3.2358e-02,\n",
      "          2.4651e-02, -4.9856e-02,  8.7855e-03,  4.5744e-02,  1.9866e-02,\n",
      "         -4.1624e-02,  4.1214e-02,  4.0299e-02, -3.6463e-02, -2.4097e-02,\n",
      "          2.5800e-02,  9.2855e-03, -4.3239e-02, -4.2526e-02, -2.6799e-02,\n",
      "         -1.1493e-02, -3.2909e-02, -1.1810e-02,  4.4541e-02, -4.7091e-02,\n",
      "          3.6555e-02,  3.9534e-02,  4.3914e-02, -3.0170e-02,  4.2659e-02,\n",
      "          5.0186e-02, -4.0190e-02, -1.9469e-02,  4.5025e-02, -3.9920e-02,\n",
      "          4.2128e-02, -9.9885e-03, -3.3303e-02, -1.0705e-02, -1.3896e-03,\n",
      "          2.4097e-02,  7.2190e-03,  1.0915e-02,  1.5309e-02,  3.2130e-02,\n",
      "          3.8482e-03,  3.1522e-03, -1.8636e-02, -4.5895e-03, -2.5310e-02,\n",
      "         -1.6294e-03,  2.8323e-02, -3.4269e-02, -4.1294e-02, -4.4087e-02,\n",
      "          1.9969e-02,  1.0694e-02, -5.4800e-02,  3.9557e-03, -8.0360e-03,\n",
      "         -5.6870e-02, -3.3642e-02,  4.4994e-02, -7.6297e-03, -3.6778e-02,\n",
      "          4.0896e-02, -3.2912e-02, -1.1340e-02, -3.8641e-02, -3.9501e-02,\n",
      "         -1.1093e-02, -4.3139e-02,  5.5273e-02,  3.4763e-03, -4.4085e-02,\n",
      "         -3.4368e-02,  1.0303e-02,  3.6556e-02,  2.8186e-03, -5.7012e-02,\n",
      "          4.8284e-02,  4.4123e-02, -4.4471e-02, -5.2574e-02, -1.4217e-02,\n",
      "          4.7937e-02, -4.4153e-02, -5.3276e-02,  4.0187e-02, -4.3687e-02,\n",
      "          4.9207e-02, -4.9787e-03, -5.5903e-03, -4.5788e-02,  4.4370e-03,\n",
      "         -3.6763e-02, -6.0877e-03, -3.5590e-02,  1.0986e-02, -2.2648e-02,\n",
      "          4.0043e-02, -4.5328e-02, -2.2681e-03, -2.1080e-02, -1.6028e-02,\n",
      "         -3.3915e-02, -4.0125e-04,  1.4781e-02,  1.5923e-02, -3.6487e-02,\n",
      "         -3.4368e-02, -2.1080e-02,  1.8155e-02,  2.0770e-02, -7.8658e-03,\n",
      "          4.3861e-02,  3.6305e-02, -2.3518e-02, -1.2996e-02, -3.3301e-02,\n",
      "         -3.8264e-02, -1.5761e-02, -3.8700e-02, -8.3571e-03,  2.6892e-02,\n",
      "          1.1889e-02,  4.9502e-02,  3.5482e-02, -1.6326e-02, -1.5106e-02,\n",
      "          5.3984e-02, -1.1567e-02,  1.4690e-02, -1.9876e-02,  3.7150e-02,\n",
      "         -1.0268e-02, -1.1934e-02,  4.1243e-02,  5.5574e-02,  3.1262e-02,\n",
      "          7.5394e-03,  3.4724e-02,  4.2850e-02, -5.0017e-02, -3.1708e-02,\n",
      "         -3.3706e-02, -7.2970e-03, -4.7923e-02, -4.5973e-02, -7.1591e-03,\n",
      "          2.1616e-02,  2.1331e-02,  4.9945e-02, -4.2705e-02, -1.9195e-02,\n",
      "          5.0578e-02,  3.5886e-02,  3.8743e-02,  3.2141e-02,  5.1859e-02],\n",
      "        [-1.1783e-02, -1.1249e-02, -4.7823e-02, -2.5811e-02, -5.4490e-02,\n",
      "          2.8891e-02, -3.8487e-02, -1.2006e-02,  4.8471e-03,  3.6763e-02,\n",
      "         -5.2964e-02,  1.5737e-02, -2.9001e-02, -3.8258e-02, -3.4358e-02,\n",
      "         -2.1151e-02,  5.4859e-02, -2.8663e-02,  8.8953e-03,  5.4895e-02,\n",
      "          2.8450e-02,  4.2033e-02, -1.1392e-02, -4.8570e-02, -5.4778e-02,\n",
      "          3.5034e-03, -3.5311e-02, -4.6087e-02, -1.7850e-02,  1.3969e-02,\n",
      "         -3.4396e-02,  1.1289e-02, -4.4193e-02,  3.6254e-03,  2.9023e-02,\n",
      "          2.0424e-02,  1.9183e-02,  4.2244e-02,  4.5924e-02, -2.6273e-02,\n",
      "          3.1088e-02, -8.2612e-03, -3.2982e-02, -4.2214e-02, -2.9279e-02,\n",
      "          4.0593e-02, -1.8885e-02,  5.1766e-02, -8.7510e-03,  3.9036e-02,\n",
      "         -2.0773e-02, -3.2189e-02, -1.9895e-02,  1.6530e-02, -5.0478e-02,\n",
      "          4.8988e-02,  1.3241e-02,  4.1479e-02,  2.7416e-02,  5.4926e-03,\n",
      "          2.9117e-03, -3.8526e-02, -9.4639e-03,  2.8678e-02, -2.8550e-02,\n",
      "          2.3617e-02, -6.2621e-03,  5.2266e-02, -4.4742e-02,  3.6507e-02,\n",
      "         -4.1391e-02, -1.4886e-02,  1.9092e-02, -5.0908e-02, -1.9228e-02,\n",
      "         -2.9014e-02, -2.5041e-02,  3.6713e-02, -1.0522e-02, -2.4337e-02,\n",
      "         -3.8258e-02,  5.0990e-02, -2.0714e-02, -1.4649e-02,  1.0896e-02,\n",
      "         -5.0043e-02, -3.2605e-02, -1.0318e-02, -1.6557e-03, -8.4032e-03,\n",
      "         -3.4807e-02,  4.3369e-02, -1.6406e-02,  1.8136e-02,  1.6273e-03,\n",
      "         -3.7371e-02,  1.5361e-03,  5.3675e-02,  4.3898e-02,  5.2252e-02,\n",
      "          3.7180e-02, -8.6412e-03,  3.6059e-02, -5.3051e-02, -1.7137e-02,\n",
      "         -5.5389e-02, -4.0961e-02, -1.8024e-02,  2.5399e-02,  2.7022e-02,\n",
      "          4.7712e-02,  2.0254e-03, -2.6130e-02,  3.1460e-02, -6.2224e-03,\n",
      "          3.8757e-02, -1.4381e-02, -4.0876e-02,  5.3356e-03,  5.5273e-02,\n",
      "         -2.6147e-02, -4.9825e-02,  2.1266e-02, -1.8458e-02, -2.7026e-02,\n",
      "         -2.0081e-02,  2.8284e-02,  2.6557e-02, -1.0009e-02,  4.1418e-02,\n",
      "          8.1933e-03,  3.0281e-02, -1.8227e-02, -5.2590e-02,  4.9001e-02,\n",
      "         -5.6056e-02, -5.4609e-02, -4.2992e-02,  4.6743e-02, -4.4474e-03,\n",
      "          4.6941e-02,  4.8055e-02,  4.8724e-02,  3.6482e-02, -4.3880e-02,\n",
      "          3.7238e-02, -3.0438e-03,  3.0644e-02, -4.8379e-02,  5.7978e-03,\n",
      "          1.7760e-03, -3.6154e-04, -5.4705e-02,  3.1829e-02,  2.8629e-02,\n",
      "         -7.5027e-03,  1.4373e-02,  1.0746e-02,  2.9230e-03,  5.4393e-02,\n",
      "          4.2445e-02, -4.2566e-02, -7.1404e-03,  3.4785e-03, -4.2774e-02,\n",
      "          4.1843e-02, -4.2765e-02,  4.6286e-02, -3.5684e-02, -1.0997e-02,\n",
      "         -3.2139e-02, -1.8887e-02, -5.4552e-02,  5.2318e-02, -4.7148e-02,\n",
      "          2.6268e-04,  9.1115e-03,  1.3113e-02,  3.4741e-02, -2.6220e-02,\n",
      "          4.7391e-02, -1.7550e-02,  8.3102e-03, -9.7668e-03,  4.2780e-02,\n",
      "          1.8302e-02, -5.2648e-02, -1.2846e-02,  6.8345e-03, -5.3433e-02,\n",
      "          8.9704e-03,  2.2491e-02,  4.2758e-02,  4.0875e-02,  3.5792e-02,\n",
      "          1.4532e-02, -5.1991e-02,  1.4694e-02, -1.1233e-02,  1.8934e-02,\n",
      "         -2.4032e-02, -3.6317e-02, -1.5621e-02, -1.1421e-02, -4.5975e-02,\n",
      "          5.5492e-02, -1.8221e-02,  5.6311e-02,  3.3381e-02,  3.4448e-02,\n",
      "         -5.7149e-04,  3.4150e-02,  2.5487e-02, -6.2762e-03,  2.1776e-02,\n",
      "          2.8707e-02,  3.0084e-02, -4.1231e-02,  5.6711e-02, -4.8835e-02,\n",
      "          1.5967e-02,  6.8778e-03, -1.3241e-02, -2.8686e-02, -3.6228e-02,\n",
      "         -7.6229e-03, -4.3113e-02,  5.4770e-02, -2.7088e-02, -2.0681e-02,\n",
      "          2.0469e-02,  1.6021e-02,  1.8685e-02,  4.8560e-02, -9.2423e-03,\n",
      "          5.1830e-02, -2.1427e-02,  2.9643e-02,  1.3026e-02, -3.6947e-02,\n",
      "         -1.0287e-02, -5.4594e-02, -2.4056e-02,  1.2154e-02, -4.7198e-02,\n",
      "         -4.9144e-02,  6.1232e-04,  2.2673e-02,  1.4082e-02, -3.4136e-03,\n",
      "         -5.0879e-02, -7.1777e-03, -7.9854e-03,  5.7343e-03,  5.6835e-02,\n",
      "          3.6799e-02,  3.8813e-02, -1.6364e-02, -3.5081e-02,  2.1723e-02,\n",
      "          2.5799e-02, -8.3015e-03, -3.1054e-02, -3.1232e-02,  2.0105e-02,\n",
      "         -4.1915e-02, -2.5098e-02, -5.3914e-02, -4.9465e-02, -4.4055e-02,\n",
      "          2.0877e-02,  2.4273e-02, -3.9872e-02, -2.1796e-02, -5.1575e-02,\n",
      "         -2.6980e-02, -2.7807e-02, -2.3719e-02,  2.9795e-03,  2.4692e-02,\n",
      "         -2.0713e-02, -7.1809e-03,  4.0930e-02,  8.4829e-05, -5.4193e-02,\n",
      "          4.8135e-02, -1.6773e-02,  2.1835e-02, -1.7411e-02, -7.5788e-03,\n",
      "          5.0652e-02,  2.6221e-02, -2.9093e-02, -2.7024e-02, -3.3930e-03,\n",
      "         -4.8170e-02,  4.0488e-02,  5.4816e-02,  3.5232e-03, -2.6827e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0250, 0.0378], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model parameters \n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee8726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
